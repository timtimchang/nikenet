{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import image_encoder\n",
    "# from image_encoder import encode_standard_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# from MBnet_test import mobilenet_v3_small\n",
    "from MBnet_val import mobilenet_v3_small\n",
    "\n",
    "def encode_standard_array(img_path):\n",
    "\n",
    "    im = cv2.imread(img_path)\n",
    "    # print(im.shape)\n",
    "    im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    # print(im.shape)\n",
    "    img_array = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    # print(x_train.shape)\n",
    "    img_array=img_array[:,:,np.newaxis]\n",
    "    img_array=img_array[np.newaxis,:,:,:]/255.0\n",
    "\n",
    "    return img_array\n",
    "\n",
    "def embed_shoe(img_array, model_path=\"./mobile_checkpoint/new_mobile_goal.ckpt\"):\n",
    "\n",
    "#     img_array = encode_standard_array(path)\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "            inputs = tf.placeholder(tf.float32, [None, 224, 224, 1]) ##輸入為四維[Batch_size,height,width,channels] \n",
    "    with tf.name_scope('stem'):\n",
    "\n",
    "        # out_triplet,out_softmax = MobileV3(inputs)\n",
    "        softmax, triplet, end_points = mobilenet_v3_small(\n",
    "            inputs, # input_test\n",
    "            103,\n",
    "            multiplier=1.0, \n",
    "            is_training=True, \n",
    "            reuse=None\n",
    "        ) # model: softmax outcome\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "            \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, model_path) \n",
    "        pred = sess.run(\n",
    "                        [triplet], \n",
    "                        feed_dict={inputs:img_array}) #list\n",
    "\n",
    "        pred = pred[0]    \n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoes class 496\n",
      "Total 103 lines with 10405 shoes.\n",
      "CPU times: user 1min 3s, sys: 2.22 s, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 06:40:10.301486 140221308585728 deprecation_wrapper.py:119] From /home/yu-theturtle/MBnet_val.py:207: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0730 06:40:10.303858 140221308585728 deprecation.py:506] From /home/yu-theturtle/tutorial4/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding....\n",
      "inputs Tensor(\"input/Placeholder:0\", shape=(?, 224, 224, 1), dtype=float32)\n",
      "input_size [224, 224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 06:40:11.117968 140221308585728 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0730 06:40:11.119240 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:62: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0730 06:40:11.358977 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:53: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0730 06:40:11.496552 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:95: separable_conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.SeparableConv2D` instead.\n",
      "W0730 06:40:11.918009 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:120: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n",
      "W0730 06:40:12.069072 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:115: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0730 06:40:15.316850 140221308585728 deprecation.py:323] From /home/yu-theturtle/MBnet_val.py:246: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0730 06:40:16.442975 140221308585728 deprecation.py:323] From /home/yu-theturtle/tutorial4/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 18s, sys: 1min 27s, total: 9min 45s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base_dir = '/home/jsamare01/DML/dataset/downloads/' # v1 test\n",
    "\n",
    "base_dir = '/home/troy0425/data/collect_new/images_all/'\n",
    "shoe_dirs_total = [\"{}{}/\".format(base_dir, dir_) for dir_ in os.listdir(base_dir) \n",
    "          if os.path.isdir(os.path.join(base_dir, dir_))]\n",
    "\n",
    "random.seed(4428)\n",
    "print(\"Shoes class\",len(shoe_dirs_total))\n",
    "random_idx = random.sample(range(len(shoe_dirs_total)), 103)\n",
    "\n",
    "# first_shoe_dirs = [shoe_dirs_total[idx] for idx in range(len(shoe_dirs_total)) if \n",
    "#               idx in random_idx]\n",
    "# second_shoe_dirs = [shoe_dirs_total[idx] for idx in range(len(shoe_dirs_total)) if \n",
    "#               idx not in random_idx]\n",
    "\n",
    "# random.seed(4428)\n",
    "# shoe_dirs_total = random.sample(shoe_dirs_total, 150)\n",
    "\n",
    "sample_dir = [shoe_dirs_total[idx] for idx in random_idx]\n",
    "shoe_dirs_total = sample_dir\n",
    "\n",
    "all_img_path = []\n",
    "for dir_ in shoe_dirs_total:\n",
    "    img_path = [\"{}{}\".format(dir_, path) for path in os.listdir(dir_)\n",
    "                if path.endswith(\".jpg\")]\n",
    "\n",
    "    for path in img_path:\n",
    "        info = path.split('/')\n",
    "        label = \"{}-{}\".format(info[-2], re.sub(\".jpg\", \"\", info[-1]))\n",
    "        all_img_path.append(\n",
    "            {\"line\": info[-2], \"label\": label, \"path\": path, \"array\": None}\n",
    "        ) # label, path, array\n",
    "\n",
    "print(\"Total {} lines with {} shoes.\".format(len(shoe_dirs_total), len(all_img_path)))\n",
    "labels = [dir_.split('/')[-2] for dir_ in shoe_dirs_total]\n",
    "\n",
    "# encode all data into array\n",
    "%time all_array = list(map(lambda img_info: encode_standard_array(img_info.get('path')),all_img_path))\n",
    "img_matrix = np.concatenate(all_array)\n",
    "print(\"Embedding....\")\n",
    "%time emb_matrix = embed_shoe(img_matrix)\n",
    "\n",
    "\n",
    "# save embedding vector\n",
    "embedding_vector_path = \"embedding_vector_496.npy\"\n",
    "np.save(embedding_vector_path, emb_matrix)\n",
    "# embedding_vector_path = \"embedding_vector_496.npy\"\n",
    "# img_matrix = np.load(embedding_vector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_shoe_dirs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e891c0f7b2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_emb_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dir_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_shoe_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msecond_emb_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dir_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_shoe_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_shoe_dirs' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "first_emb_matrix = embed_dir_images(first_shoe_dirs)\n",
    "gc.collect()\n",
    "second_emb_matrix = embed_dir_images(second_shoe_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_emb_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aca2c5fc97d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_emb_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_emb_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'first_emb_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "np.concatenate((first_emb_matrix, second_emb_matrix)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time emb_matrix = embed_shoe(img_matrix)\n",
    "\n",
    "sample_path = \"all_embeddind_100line_sample_v2.npy\"\n",
    "\n",
    "np.save(sample_path, emb_matrix)\n",
    "emb_matrix = np.load(sample_path)\n",
    "\n",
    "print(emb_matrix.shape)\n",
    "print(len(all_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_shoe(all_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for array, img_info in zip(emb_matrix, all_img_path):\n",
    "    img_info['array'] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_img_path))\n",
    "all_img_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' each line with its embedding matrix from image '''\n",
    "line_df = []\n",
    "all_line = [line_str.split('/')[-2] for line_str in shoe_dirs_total]\n",
    "for line in all_line:\n",
    "    target_info_list = [img_info.get('array') for img_info in all_img_path \n",
    "                     if img_info.get('path').split('/')[-2] == line]\n",
    "    all_matrix = np.vstack(target_info_list)\n",
    "    line_df.append({\"label\": line, \"emb_matrix\": all_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(line_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Image Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named bs4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-10ca0c9990f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named bs4"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_img_url(keyword):\n",
    "    '''\n",
    "    Input : keyword in string format\n",
    "    Output: url in string format\n",
    "    '''\n",
    "# keyword = \"Nike Air Max\"\n",
    "    keyword = \"+\".join([token.lower() for token in keyword.split(' ')])\n",
    "    query = \"https://www.google.com/search?biw=1280&bih=688&tbs=isz%3Ai&tbm=isch&sa=1&ei=pKs9XdC0H6WImAWYmrXgCg&q={}x&oq={}&gs_l=img.12...0.0..7026...0.0..0.0.0.......0......gws-wiz-img.0DrM6W-zvnU&ved=0ahUKEwjQlryi5NfjAhUlBKYKHRhNDawQ4dUDCAY\".format(\n",
    "            keyword, keyword)\n",
    "\n",
    "    page = requests.get(query).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    img_url = soup.find(\"img\")['src']\n",
    "    \n",
    "    return img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-922ad39de9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshoe_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawl_img_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nike SB Dunk High Elite-8641'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshoe_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e8787195b8c7>\u001b[0m in \u001b[0;36mcrawl_img_url\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "shoe_url = crawl_img_url('Nike SB Dunk High Elite-8641')\n",
    "print(shoe_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Whispers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_distance(face_encodings, face_to_compare):\n",
    "    \"\"\"\n",
    "    计算一组特征值与带比较特征值之间的距离，默认采用欧氏距离\n",
    "    参数配置\n",
    "    face_encodings:一组特征值，包含多个\n",
    "    face_to_compare:待比较特征值，只有一个\n",
    "    return:返回不同特征向量之间距离的数组矩阵\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "    '''\n",
    "    利用numpy包进行距离估量\n",
    "    http://blog.csdn.net/u013749540/article/details/51813922\n",
    "    '''\n",
    "    dist=[]\n",
    "\n",
    "    \"\"\"\n",
    "    # 欧氏距离，考虑后续邻接边选择weight较大者，此处选取余弦相似度\n",
    "    for i in range(0,len(face_encodings)):\n",
    "        #sim = 1.0/(1.0+np.linalg.norm(face_encodings[i]-face_to_compare))\n",
    "        sim=np.linalg.norm(face_encodings[i]-face_to_compare)\n",
    "        dist.append(sim)\n",
    "    \"\"\"\n",
    "    # 余弦相似度\n",
    "    for i in range(0, len(face_encodings)):\n",
    "        num=np.dot(face_encodings[i],face_to_compare)\n",
    "        cos=num/(np.linalg.norm(face_encodings[i])*np.linalg.norm(face_to_compare))\n",
    "        sim=0.5+0.5*cos # 归一化\n",
    "        dist.append(sim)\n",
    "    return dist\n",
    "\n",
    "def find_all_index(arr,item):\n",
    "    '''获取list中相同元素的索引\n",
    "    输入：\n",
    "        arr：待求取list\n",
    "        item：待获取元素\n",
    "\n",
    "    输出：\n",
    "        相同元素索引，格式为list'''\n",
    "    return [i for i, a in enumerate(arr) if a==item]\n",
    "\n",
    "def _chinese_whispers(emb_matrix, threshold=0.675, iterations=10):\n",
    "    \"\"\" Chinese Whisper Algorithm\n",
    "    算法概要\n",
    "        1.初始化每个节点为一个类\n",
    "        2.选取任意节点开始迭代\n",
    "            选择该节点邻居中边权重最大者，将两则归为一类；若邻居中有2者以上属于同一类，将这些类权重相加进行比较\n",
    "\n",
    "    输入：\n",
    "        encoding_list:待分类的特征向量组\n",
    "        threshold:判断门限，判断两个向量是否相关\n",
    "        iteration:迭代次数\n",
    "\n",
    "    输出：\n",
    "        sorted_clusters:一组分类结果，按从大到小排列\n",
    "    \"\"\"\n",
    "\n",
    "    from random import shuffle\n",
    "    import networkx as nx\n",
    "    import numpy as np\n",
    "    import re\n",
    "    print('Clustering With {} embeddings.'.format(emb_matrix.shape[0]))\n",
    "    # Create graph\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    #encoding_list格式为\n",
    "    #[(path1,encode1),(path2,encode2),(path3,encode3)]\n",
    "    #image_paths, encodings = zip(*encoding_list)\n",
    "    feature_matrix=emb_matrix\n",
    "    encodings=[]\n",
    "    #image_paths=[]\n",
    "    for i in range(0,len(feature_matrix)):\n",
    "        encodings.append(feature_matrix[i,:])\n",
    "        #image_paths.append(r'F:\\outCluster\\%d\\\\' %i)\n",
    "\n",
    "    if len(encodings) <= 1:\n",
    "        print (\"No enough encodings to cluster!\")\n",
    "        return []\n",
    "\n",
    "    ''' \n",
    "    节点初始化：\n",
    "        1.将每个特征向量设为一个类\n",
    "        2.计算每个特征向量之间的距离，并根据门限判定是否构成邻接边\n",
    "    '''\n",
    "    local_farest = []\n",
    "    local_nearest = []\n",
    "    \n",
    "    for idx, face_encoding_to_check in enumerate(encodings):\n",
    "        # Adding node of facial encoding\n",
    "        node_id = idx\n",
    "\n",
    "        # 节点属性包括\n",
    "        # node_id:节点id,(0,n-1)\n",
    "        # label:节点类别，初始化每个节点一个类别\n",
    "        # path：节点导出路径，用于图片分类导出\n",
    "        node = (node_id, {'label':idx})\n",
    "        #node = (node_id, {'label': idx, 'path': image_paths[idx]})\n",
    "        nodes.append(node)\n",
    "\n",
    "        # Facial encodings to compare\n",
    "        if (idx+1) >= len(encodings):\n",
    "            # Node is last element, don't create edge\n",
    "            break\n",
    "\n",
    "        #构造比较向量组\n",
    "        #若当前向量为i,则比较向量组为[i+1:n]\n",
    "        compare_encodings = encodings[idx+1:]\n",
    "        distances = face_distance(compare_encodings, face_encoding_to_check)\n",
    "        encoding_edges = []\n",
    "        for i, distance in enumerate(distances):\n",
    "            # 若人脸特征匹配，则在这两个节点间添加关联边\n",
    "            if distance >= threshold:\n",
    "                #edge_id：与node_id相连接的节点的node_id\n",
    "                edge_id = idx+i+1\n",
    "                encoding_edges.append((node_id, edge_id, {'weight': distance}))\n",
    "        local_farest.append(np.max(distance))\n",
    "        local_nearest.append(np.min(distance))\n",
    "        edges = edges + encoding_edges\n",
    "\n",
    "    print(\"Pointwise Distance Max Farest: {}\".format(max(local_farest)))\n",
    "#     print('Mean Farest: {}'.format(np.mean(local_farest)))\n",
    "#     print(\"Min Farest: {}\".format(min(local_farest)))\n",
    "\n",
    "#     print(\"Max Nearest: {}\".format(max(local_nearest)))\n",
    "#     print('Mean Nearest: {}'.format(np.mean(local_nearest)))\n",
    "    print(\"Pointwise Distance Min Nearest: {}\".format(min(local_nearest)))\n",
    "    print(\"Farest - Nearest Distance: {}\".format(max(local_farest) - min(local_nearest)))\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    '''\n",
    "    迭代过程\n",
    "\n",
    "    '''\n",
    "    for _ in range(0, iterations):\n",
    "        cluster_nodes = list(G.nodes()) #返回节点id\n",
    "        shuffle(cluster_nodes)# 随机选取一个开始节点\n",
    "        for node in cluster_nodes:\n",
    "            # 当前节点的所有邻接边，如节点4邻接边为(4,5,weight=8)(4,8,weight=10)\n",
    "            # 则G[4]返回值为AtlasView({5:{'weight':8}, 8:{'weight':10}})\n",
    "            neighbors = G[node]\n",
    "            # cluster形式\n",
    "            # {'cluster_path':weight}   其中cluster_paht=node属性的cluster值\n",
    "            labels = {}\n",
    "\n",
    "            for ne in neighbors: # ne即为当前节点邻接的节点id\n",
    "                if isinstance(ne, int):\n",
    "                    '''\n",
    "                    判断该邻居的类别是否在其他邻居中存在\n",
    "                        若存在，则将相同类别的权重相加。\n",
    "                    '''\n",
    "                    if G.node[ne]['label'] in labels:#G.node[ne]['label']即为id=ne节点的label属性\n",
    "                        labels[G.node[ne]['label']] += G[node][ne]['weight']#将这条邻接边(node,ne)的weight属性赋值给cluster[节点ne的cluster]\n",
    "                    else:\n",
    "                        labels[G.node[ne]['label']] = G[node][ne]['weight']\n",
    "\n",
    "            # find the class with the highest edge weight sum\n",
    "            edge_weight_sum = 0\n",
    "            max_cluster = 0\n",
    "            #将邻居节点的权重最大值对应的文件路径给到当前节点\n",
    "            #这里cluster即为path\n",
    "            for id in labels:\n",
    "                if labels[id] > edge_weight_sum:\n",
    "                    edge_weight_sum = labels[id]\n",
    "                    max_cluster = id\n",
    "\n",
    "            # set the class of target node to the winning local class\n",
    "            #print('node %s was clustered in %s' %(node, max_cluster))\n",
    "            G.node[node]['label'] = max_cluster\n",
    "    list_label_out = []\n",
    "    for i in range(len(encodings)):\n",
    "        list_label_out.append(G.node[i]['label'])\n",
    "    #print(list_label_out)\n",
    "\n",
    "    ''' \n",
    "\n",
    "    统计分类错误数量=新类别中不属于原类别的数量      eg： list_label_out=[1,3,4,2,2,4,3,1]\n",
    "    # group_all 返回最终类别标签                     group_all=[1,2,3,4]\n",
    "    # group_num 最终分类数量                        group_num=4\n",
    "    # group_cluster: list,返回相同标签的节点id       group_cluster=[[0,7],[3,4],[1,6],[2,5]]\n",
    "    '''\n",
    "    group_all = set(list_label_out)\n",
    "    group_num = len(group_all)\n",
    "    group_cluster = []\n",
    "\n",
    "    for item in group_all:\n",
    "        group_cluster.append(find_all_index(list_label_out,item))\n",
    "\n",
    "    centroid_list = []\n",
    "    print('最終分類數量：%s' %group_num)\n",
    "    for i in range(0,group_num):\n",
    "        print('第%d類：%s'%(i,group_cluster[i]))\n",
    "        centroid = emb_matrix[group_cluster[i]].mean(axis=0)\n",
    "        centroid_list.append(centroid)\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    return np.vstack(centroid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def variance_of_laplacian(image):\n",
    "#     # compute the Laplacian of the image and then return the focus\n",
    "#     # measure, which is simply the variance of the Laplacian\n",
    "#     return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_var_matrix = []\n",
    "# for idx in range(100):\n",
    "#     test_emb_var = line_df[idx].get('emb_matrix').var(axis=0)\n",
    "#     print(\"Mean: {}\".format(np.mean(test_emb_var)))\n",
    "#     print(\"Var: {} \\n\".format(test_emb_var.var()))\n",
    "#     emb_var_matrix.append(test_emb_var)\n",
    "    \n",
    "# emb_var_df = pd.DataFrame(emb_var_matrix)\n",
    "# emb_var_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_var_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-330e7eb00eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_var_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_var_df' is not defined"
     ]
    }
   ],
   "source": [
    "emb_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0 line Nike Zoom Kobe 7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4acd4609f9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For {} line {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlocal_emb_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'emb_matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(\"Mean: {}\".format(np.mean(test_emb_var)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlocal_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_emb_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# not be either.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         arrmean = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "for idx, line_info in enumerate(line_df):\n",
    "    print('For {} line {}'.format(idx, line_info.get('label')))\n",
    "    local_emb_var = line_info.get('emb_matrix').var(axis=0)\n",
    "#     print(\"Mean: {}\".format(np.mean(test_emb_var)))\n",
    "    local_threshold = np.mean(local_emb_var)\n",
    "    print(\"Threshold: {}\".format(local_threshold))\n",
    "    centroid_list = _chinese_whispers(line_info.get('emb_matrix'), \n",
    "                     threshold= 0.6,\n",
    "                     iterations= 100)\n",
    "#     print(centroid_list.shape)\n",
    "    line_info[\"centroids\"] = centroid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-293ac90fa757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcent_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'centroids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mcent_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"line\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"centroid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'line_df' is not defined"
     ]
    }
   ],
   "source": [
    "''' Save File of each embedding '''\n",
    "import pandas as pd \n",
    "cent_df = []\n",
    "for info in line_df:\n",
    "    for cent in info.get('centroids'):\n",
    "         cent_df.append({\"line\": info.get('label'), \"centroid\": cent})\n",
    "cent_df = pd.DataFrame(cent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centro_matrix = np.array(cent_df.centroid.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centro_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"50_lines_centroids.npy\", centro_matrix)\n",
    "# cent_df.line.to_csv('50_line_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Find the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_df.loc[cent_df.line.apply(lambda line: \"Nike Air Huarache\" in line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = 'Nike Huarache Trainer Free.jpg'\n",
    "img_array = encode_standard_array(test_img_path)\n",
    "# img_array = (img_array/255.0)\n",
    "test_array = embed_shoe(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1d539199b8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_array' is not defined"
     ]
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'centro_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5587b05861a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentro_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'centro_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_matrix = cosine_similarity(test_array, centro_matrix)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix[sim_matrix.argsort()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_rank = list(sim_matrix.argsort()[-11:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sim_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, rank in enumerate(sim_rank):\n",
    "    print('The {} candidates is {}'.format(idx, cent_df.iloc[rank].line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Select photo to compare with top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shoe_dirs_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71ae9d8dd693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtesting_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrdm_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdir_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshoe_dirs_total\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     img_path = [\"{}{}\".format(dir_, path) for path in os.listdir(dir_)\n\u001b[1;32m      7\u001b[0m                 if path.endswith(\".jpg\")]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shoe_dirs_total' is not defined"
     ]
    }
   ],
   "source": [
    "# shoe_dirs_total = sample_dir\n",
    "\n",
    "testing_img_path = []\n",
    "rdm_num = 10\n",
    "for dir_ in shoe_dirs_total:\n",
    "    img_path = [\"{}{}\".format(dir_, path) for path in os.listdir(dir_)\n",
    "                if path.endswith(\".jpg\")]\n",
    "    img_path = random.sample(img_path, rdm_num)\n",
    "    for path in img_path:\n",
    "        info = path.split('/')\n",
    "        label = \"{}-{}\".format(info[-2], re.sub(\".jpg\", \"\", info[-1]))\n",
    "        testing_img_path.append(\n",
    "            {\"line\": info[-2], \"label\": label, \"path\": path, \"array\": None}\n",
    "        ) # label, path, array\n",
    "\n",
    "print(\"Total {} lines with {} shoes.\".format(len(shoe_dirs_total), len(testing_img_path)))\n",
    "# testing_labels = [dir_.split('/')[-2] for dir_ in shoe_dirs_total]\n",
    "\n",
    "# encode all data into array\n",
    "\n",
    "%time testing_array = list(map(lambda img_info: encode_standard_array(img_info.get('path')),testing_img_path))\n",
    "testing_img_matrix = np.concatenate(testing_array)\n",
    "%time testing_emb_matrix = embed_shoe(testing_img_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/troy0425/data/collect_new/images/Nike Air Footscape Woven/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Penny 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Up/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Bo 1/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LunarGlide+ 3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike SB Eric Koston 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Tech Challenge Hybrid/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max CB34 II/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Flight 13/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Free Flyknit/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Hyperdunk 2012/',\n",
       " '/home/troy0425/data/collect_new/images/Nike React Element 55/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Light/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Free 3.0 V3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Hyperaggressor/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Uptempo Fuse 360/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Flyknit Trainer Chukka/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max 98/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max LeBron 8/',\n",
       " '/home/troy0425/data/collect_new/images/Nike SB Air Force 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom LeBron 4/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Flyknit Trainer/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron Soldier 12/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air VaporMax 95/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Kukini/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Mercurial TN/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Hyperdunk 2016/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Lunar Flyknit Chukka/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron x John Elliott Icon/',\n",
       " '/home/troy0425/data/collect_new/images/Nike SB Omar Salazar/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Huarache Bball 2012/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Trainer V Cruz 1/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max 2016/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max 360 Trainer 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Blazer/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Hyperdunk 2010/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Okwahn 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Penny/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Presto Flyknit Ultra/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Hyperposite/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom Fly/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Trainer 3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom All Out Flyknit/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron 14/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Flight Bonafide/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max BW/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Shark Trainer/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom Vapor 9 Tour/',\n",
       " '/home/troy0425/data/collect_new/images/Nike JBJ Free 5.0 TR/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Phantom React Flyknit/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Field General 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Zero/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Toki/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Zoom Flight 96/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Conquer/',\n",
       " '/home/troy0425/data/collect_new/images/Nike KD Trey 5 III/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Killshot/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Uptempo 97/',\n",
       " '/home/troy0425/data/collect_new/images/Nike ISPA React Low/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Footscape Magista/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LunarFly 306/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Trainer 2/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Lunar Hypergamer/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Mission/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron 10/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Solarsoft Moccasin/',\n",
       " '/home/troy0425/data/collect_new/images/Nike SB Paul Rodriguez 9/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Free Transform Flyknit/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Lunar Force 1 Low/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron 11/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Payaa/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air VaporMax 97/',\n",
       " '/home/troy0425/data/collect_new/images/Nike ACG 07 KMTR/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Pillar/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max 90/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Free Run+ 3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Tennis Classic 12/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom LeBron 6/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Lunar Solstice/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max 2013/',\n",
       " '/home/troy0425/data/collect_new/images/Nike KD 8/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Audacity/',\n",
       " '/home/troy0425/data/collect_new/images/Nike React Hyperdunk 2017/',\n",
       " '/home/troy0425/data/collect_new/images/Nike SB Project BA/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom Run The One/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Roshe Two/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Roshe Run/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom Field General/',\n",
       " '/home/troy0425/data/collect_new/images/Nike ACG Ruckel Ridge/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron 15/',\n",
       " '/home/troy0425/data/collect_new/images/Nike KD 8 Elite/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Humara/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Lunar Huarache Light/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Shake Evolve/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air 3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Flight Huarache Ultra/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Unlimited/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Shox TLX/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LunarEpic Flyknit/',\n",
       " '/home/troy0425/data/collect_new/images/Nike LeBron 13 Elite/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Max Courtballistec 4.3/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Zoom Streak Spectrum Plus/',\n",
       " '/home/troy0425/data/collect_new/images/Nike Air Scream LWP/']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe_dirs_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs Tensor(\"input/Placeholder:0\", shape=(?, 224, 224, 1), dtype=float32)\n",
      "input_size [224, 224]\n"
     ]
    }
   ],
   "source": [
    "test_img_path = 'Nike KD 8 test.jpg'\n",
    "img_array = encode_standard_array(test_img_path)\n",
    "# img_array = (img_array/255.0)\n",
    "test_array = embed_shoe(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.524671  ,   3.114753  ,   2.2914023 , ...,  -6.759872  ,\n",
       "         -3.70871   ,   0.6850882 ],\n",
       "       [  1.7791815 ,  -0.8430152 , -22.551268  , ..., -19.224007  ,\n",
       "         -0.5281583 ,  -4.8942475 ],\n",
       "       [ -1.4716938 ,  21.651424  ,  -0.90004283, ...,  18.32589   ,\n",
       "        -39.80056   , -27.024124  ],\n",
       "       ...,\n",
       "       [-11.117239  ,  18.874275  , -15.765719  , ...,  19.803226  ,\n",
       "         -5.683696  ,  11.248133  ],\n",
       "       [ -7.256352  ,  -8.146556  ,  -2.2535844 , ...,  18.97243   ,\n",
       "         -8.077344  , -23.640623  ],\n",
       "       [ -8.662808  ,  -7.941438  , -17.01536   , ...,   9.497304  ,\n",
       "         -1.985655  ,  -1.9609196 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161.03671, 135.51222, 206.38152, 146.15671, 158.01987, 116.69546, 154.05438, 236.15955, 97.88451, 154.12987, 107.325455, 112.4235, 163.80966, 153.44035, 154.76183, 148.61826, 122.91362, 144.8728, 129.66614, 149.48132, 133.86456, 238.87549, 117.51796, 223.01811, 177.34512, 151.32593, 168.51779, 175.75314, 140.45786, 127.32655, 134.70435, 144.93622, 158.5477, 132.51534, 253.60214, 149.15485, 129.0585, 164.32376, 240.5312, 119.64177, 145.50797, 172.42046, 156.15817, 108.14319, 186.62302, 137.62701, 183.42642, 177.9924, 120.16632, 187.19756, 126.30847, 97.58478, 172.0042, 191.41177, 121.1083, 187.58113, 177.1094, 223.43344, 123.45354, 128.83255, 178.4444, 121.87982, 171.66072, 163.16068, 147.39055, 133.84857, 95.742874, 175.87498, 125.11238, 125.84275, 207.41458, 219.19919, 198.04279, 119.49104, 161.6844, 134.83304, 176.46767, 115.50924, 128.17838, 158.61844, 107.17969, 135.28328, 177.48628, 156.13171, 173.70137, 110.77806, 126.37565, 113.44563, 117.42228, 119.510056, 115.444725, 110.43015, 126.65996, 160.16278, 239.86417, 121.71078, 158.01602, 192.97098, 161.76184, 168.29037, 176.78242, 138.25403, 135.23961]\n"
     ]
    }
   ],
   "source": [
    "# np.apply_along_axis(lambda x: , 0, test_array)\n",
    "similarity_list = []\n",
    "local_min_list = []\n",
    "\n",
    "local_simi_list = []\n",
    "for idx, emb in enumerate(testing_emb_matrix):\n",
    "    if (idx % rdm_num == 0) and (idx != 0): \n",
    "#         local_simi_list = []\n",
    "        \n",
    "        #local_min_list.append(np.mean(local_simi_list))\n",
    "        local_simi_list.sort()\n",
    "        local_simi_list = local_min_list[:10]\n",
    "        local_min_list.append(np.mean(local_simi_list))\n",
    "        local_simi_list = []\n",
    "        \n",
    "    similarity = np.linalg.norm(emb - test_array)\n",
    "    \n",
    "#     print(\"Distance to {}: {}\".format(line_list[idx], similarity))\n",
    "#     similarity_list.append(similarity)\n",
    "    local_simi_list.append(similarity)\n",
    "    \n",
    "local_min_list.append(np.mean(local_simi_list))    \n",
    "# similarity_list = np.array(similarity_list)\n",
    "# simi_rank = similarity_list.argsort()[-30:][::-1]\n",
    "\n",
    "print(local_min_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Nike Air Footscape Magista</td>\n",
       "      <td>0.389345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>Nike ACG 07 KMTR</td>\n",
       "      <td>0.391484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>Nike Hyperdunk 2010</td>\n",
       "      <td>0.397950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>Nike ACG Ruckel Ridge</td>\n",
       "      <td>0.400407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>Nike Hyperdunk 2016</td>\n",
       "      <td>0.410608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Nike React Element 55</td>\n",
       "      <td>0.415401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>Nike Zoom Field General</td>\n",
       "      <td>0.417247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>Nike Air Unlimited</td>\n",
       "      <td>0.421231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98</td>\n",
       "      <td>Nike LunarEpic Flyknit</td>\n",
       "      <td>0.425396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>Nike Shox TLX</td>\n",
       "      <td>0.428262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>69</td>\n",
       "      <td>Nike LeBron 11</td>\n",
       "      <td>0.429711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89</td>\n",
       "      <td>Nike LeBron 15</td>\n",
       "      <td>0.433301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>102</td>\n",
       "      <td>Nike Air Scream LWP</td>\n",
       "      <td>0.433767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61</td>\n",
       "      <td>Nike Air Trainer 2</td>\n",
       "      <td>0.434081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>Nike Air Trainer V Cruz 1</td>\n",
       "      <td>0.439856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74</td>\n",
       "      <td>Nike Air Max 90</td>\n",
       "      <td>0.446921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27</td>\n",
       "      <td>Nike Lunar Flyknit Chukka</td>\n",
       "      <td>0.451612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>57</td>\n",
       "      <td>Nike Air Max Uptempo 97</td>\n",
       "      <td>0.451727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63</td>\n",
       "      <td>Nike Air Mission</td>\n",
       "      <td>0.454602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike Air Bo 1</td>\n",
       "      <td>0.455656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>84</td>\n",
       "      <td>Nike Zoom Run The One</td>\n",
       "      <td>0.457387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike Air Footscape Woven</td>\n",
       "      <td>0.458784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53</td>\n",
       "      <td>Nike Air Zoom Flight 96</td>\n",
       "      <td>0.460727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82</td>\n",
       "      <td>Nike React Hyperdunk 2017</td>\n",
       "      <td>0.463155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>Nike Air Shark Trainer</td>\n",
       "      <td>0.464020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>94</td>\n",
       "      <td>Nike Air 3</td>\n",
       "      <td>0.464468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43</td>\n",
       "      <td>Nike LeBron 14</td>\n",
       "      <td>0.465237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>Nike Flyknit Trainer Chukka</td>\n",
       "      <td>0.465829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>Nike Air Huarache Bball 2012</td>\n",
       "      <td>0.472156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42</td>\n",
       "      <td>Nike Zoom All Out Flyknit</td>\n",
       "      <td>0.472720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>12</td>\n",
       "      <td>Nike Air Max Light</td>\n",
       "      <td>0.570632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>79</td>\n",
       "      <td>Nike Air Max 2013</td>\n",
       "      <td>0.571406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10</td>\n",
       "      <td>Nike Hyperdunk 2012</td>\n",
       "      <td>0.579715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9</td>\n",
       "      <td>Nike Free Flyknit</td>\n",
       "      <td>0.581096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>67</td>\n",
       "      <td>Nike Free Transform Flyknit</td>\n",
       "      <td>0.583632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>20</td>\n",
       "      <td>Nike Zoom LeBron 4</td>\n",
       "      <td>0.583842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>92</td>\n",
       "      <td>Nike Lunar Huarache Light</td>\n",
       "      <td>0.585107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>45</td>\n",
       "      <td>Nike Air Max BW</td>\n",
       "      <td>0.585906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>54</td>\n",
       "      <td>Nike Air Max Conquer</td>\n",
       "      <td>0.586220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>70</td>\n",
       "      <td>Nike Payaa</td>\n",
       "      <td>0.586970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>76</td>\n",
       "      <td>Nike Tennis Classic 12</td>\n",
       "      <td>0.591354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>60</td>\n",
       "      <td>Nike LunarFly 306</td>\n",
       "      <td>0.591714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18</td>\n",
       "      <td>Nike Air Max LeBron 8</td>\n",
       "      <td>0.595167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>39</td>\n",
       "      <td>Nike Air Max Hyperposite</td>\n",
       "      <td>0.597749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>65</td>\n",
       "      <td>Nike Solarsoft Moccasin</td>\n",
       "      <td>0.598497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>85</td>\n",
       "      <td>Nike Roshe Two</td>\n",
       "      <td>0.599373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "      <td>Nike LunarGlide+ 3</td>\n",
       "      <td>0.602133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>17</td>\n",
       "      <td>Nike Air Max 98</td>\n",
       "      <td>0.604640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>32</td>\n",
       "      <td>Nike Air Max 2016</td>\n",
       "      <td>0.605955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>100</td>\n",
       "      <td>Nike Air Max Courtballistec 4.3</td>\n",
       "      <td>0.606222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>19</td>\n",
       "      <td>Nike SB Air Force 2</td>\n",
       "      <td>0.608201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>Nike SB Eric Koston 2</td>\n",
       "      <td>0.614408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83</td>\n",
       "      <td>Nike SB Project BA</td>\n",
       "      <td>0.615089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>68</td>\n",
       "      <td>Nike Lunar Force 1 Low</td>\n",
       "      <td>0.617960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>51</td>\n",
       "      <td>Nike Air Max Zero</td>\n",
       "      <td>0.618032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>21</td>\n",
       "      <td>Nike Flyknit Trainer</td>\n",
       "      <td>0.621284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>66</td>\n",
       "      <td>Nike SB Paul Rodriguez 9</td>\n",
       "      <td>0.639031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>38</td>\n",
       "      <td>Nike Air Presto Flyknit Ultra</td>\n",
       "      <td>0.652139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>86</td>\n",
       "      <td>Nike Roshe Run</td>\n",
       "      <td>0.677098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>47</td>\n",
       "      <td>Nike Zoom Vapor 9 Tour</td>\n",
       "      <td>0.715544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                             Name  Similarity\n",
       "0       59       Nike Air Footscape Magista    0.389345\n",
       "1       72                 Nike ACG 07 KMTR    0.391484\n",
       "2       35              Nike Hyperdunk 2010    0.397950\n",
       "3       88            Nike ACG Ruckel Ridge    0.400407\n",
       "4       26              Nike Hyperdunk 2016    0.410608\n",
       "5       11            Nike React Element 55    0.415401\n",
       "6       87          Nike Zoom Field General    0.417247\n",
       "7       96               Nike Air Unlimited    0.421231\n",
       "8       98           Nike LunarEpic Flyknit    0.425396\n",
       "9       97                    Nike Shox TLX    0.428262\n",
       "10      69                   Nike LeBron 11    0.429711\n",
       "11      89                   Nike LeBron 15    0.433301\n",
       "12     102              Nike Air Scream LWP    0.433767\n",
       "13      61               Nike Air Trainer 2    0.434081\n",
       "14      31        Nike Air Trainer V Cruz 1    0.439856\n",
       "15      74                  Nike Air Max 90    0.446921\n",
       "16      27        Nike Lunar Flyknit Chukka    0.451612\n",
       "17      57          Nike Air Max Uptempo 97    0.451727\n",
       "18      63                 Nike Air Mission    0.454602\n",
       "19       3                    Nike Air Bo 1    0.455656\n",
       "20      84            Nike Zoom Run The One    0.457387\n",
       "21       0         Nike Air Footscape Woven    0.458784\n",
       "22      53          Nike Air Zoom Flight 96    0.460727\n",
       "23      82        Nike React Hyperdunk 2017    0.463155\n",
       "24      46           Nike Air Shark Trainer    0.464020\n",
       "25      94                       Nike Air 3    0.464468\n",
       "26      43                   Nike LeBron 14    0.465237\n",
       "27      16      Nike Flyknit Trainer Chukka    0.465829\n",
       "28      30     Nike Air Huarache Bball 2012    0.472156\n",
       "29      42        Nike Zoom All Out Flyknit    0.472720\n",
       "..     ...                              ...         ...\n",
       "73      12               Nike Air Max Light    0.570632\n",
       "74      79                Nike Air Max 2013    0.571406\n",
       "75      10              Nike Hyperdunk 2012    0.579715\n",
       "76       9                Nike Free Flyknit    0.581096\n",
       "77      67      Nike Free Transform Flyknit    0.583632\n",
       "78      20               Nike Zoom LeBron 4    0.583842\n",
       "79      92        Nike Lunar Huarache Light    0.585107\n",
       "80      45                  Nike Air Max BW    0.585906\n",
       "81      54             Nike Air Max Conquer    0.586220\n",
       "82      70                       Nike Payaa    0.586970\n",
       "83      76           Nike Tennis Classic 12    0.591354\n",
       "84      60                Nike LunarFly 306    0.591714\n",
       "85      18            Nike Air Max LeBron 8    0.595167\n",
       "86      39         Nike Air Max Hyperposite    0.597749\n",
       "87      65          Nike Solarsoft Moccasin    0.598497\n",
       "88      85                   Nike Roshe Two    0.599373\n",
       "89       4               Nike LunarGlide+ 3    0.602133\n",
       "90      17                  Nike Air Max 98    0.604640\n",
       "91      32                Nike Air Max 2016    0.605955\n",
       "92     100  Nike Air Max Courtballistec 4.3    0.606222\n",
       "93      19              Nike SB Air Force 2    0.608201\n",
       "94       5            Nike SB Eric Koston 2    0.614408\n",
       "95      83               Nike SB Project BA    0.615089\n",
       "96      68           Nike Lunar Force 1 Low    0.617960\n",
       "97      51                Nike Air Max Zero    0.618032\n",
       "98      21             Nike Flyknit Trainer    0.621284\n",
       "99      66         Nike SB Paul Rodriguez 9    0.639031\n",
       "100     38    Nike Air Presto Flyknit Ultra    0.652139\n",
       "101     86                   Nike Roshe Run    0.677098\n",
       "102     47           Nike Zoom Vapor 9 Tour    0.715544\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df = []\n",
    "for idx, distance in enumerate(local_min_list):\n",
    "#     print(\"Distance for {}: {}\".format((shoe_dirs_total[i`x]).split('/')[-2], \n",
    "#                                        distance))\n",
    "    dist_df.append({\"Name\": (shoe_dirs_total[idx]).split('/')[-2], \n",
    "                    \"Similarity\": distance})\n",
    "    \n",
    "dist_df = pd.DataFrame(dist_df)\n",
    "dist_df.sort_values(by=['Similarity']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simi_rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2d90ea5733a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimi_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Candidates: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simi_rank' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, rank in enumerate(simi_rank):\n",
    "    print('{} Candidates: {}'.format(idx, line_list[rank]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_emb_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-23318bcd6876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting_emb_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_emb_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "testing_emb_matrix(np.linalg.norm(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a6adc10d2565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting_simi_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_emb_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtesting_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtesting_simi_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_array' is not defined"
     ]
    }
   ],
   "source": [
    "testing_simi_matrix = cosine_similarity(test_array, testing_emb_matrix)[0]\n",
    "testing_rank = (testing_simi_matrix.argsort())[-11:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_simi_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-be5067d00065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_simi_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_simi_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "len(testing_simi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_list = list(np.repeat(shoe_dirs_total, 10))\n",
    "line_list = [line.split('/')[-2] for line in line_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f297d0431434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The {} candidates is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_rank' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, rank in enumerate(testing_rank):\n",
    "    print('The {} candidates is {}'.format(idx, line_list[rank]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_shoe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2daaf0b04167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Nike Air Penny {}.jpg\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_shoe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_standard_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0memb_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_shoe' is not defined"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for img_idx in ['1', '2', '3', '4']:\n",
    "    file_path = \"Nike Air Penny {}.jpg\".format(img_idx)\n",
    "    emb = embed_shoe(encode_standard_array(file_path))\n",
    "    emb_list.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (4,128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-89324a56ba1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (4,128)"
     ]
    }
   ],
   "source": [
    "emb_list = np.array(emb_list).reshape(4, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-cea02f08a655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         X = Y = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 108\u001b[0;31m                             warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "cosine_similarity(np.array(emb_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
